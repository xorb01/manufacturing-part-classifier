## 🍀 프로젝트 개요

- **배경:** 제조 현장에서 사용되는 대량의 부품(Product A, B)을 자동 분류하여 공정 효율화 추진.
- **핵심 역할:** 클러스터링 분석을 통한 데이터 분포 분석 및 YOLO 모델의 라벨링 전략 수정을 통한 분류 신뢰도 확보.


## 🔧 기술 스택

| **분류** | **기술 스택** | **주요 역할 및 활용 이유** |
| --- | --- | --- |
| **Language** | **Python** | 데이터 전처리, 모델 학습 및 분석 파이프라인 구축을 위한 메인 언어 |
| **Framework** | **PyTorch** | YOLOv8 및 ResNet50 모델 구현 및 딥러닝 학습 환경 구축 |
| **Feature Extraction** | **ResNet50** | 제조 부품 이미지로부터 고차원 특징 벡터를 추출하여 데이터 분석에 활용 |
| **Visualization** | **t-SNE** | 고차원의 데이터를 2차원으로 축소하여 제품 A/B 간의 군집 중첩 현상을 시각화 |
| **Clustering** | **K-means** | 추출된 특징 데이터를 바탕으로 레이블 없이 부품 간 유사성을 그룹화하여 분포 확인 |
| **Object Detection** | **YOLOv8** | 실시간 객체 탐지 및 정밀 분류를 수행하는 메인 지도 학습 모델로 활용 |
| **Labeling Tool** | **LabelImg** | 바운딩 박스 기반의 학습 데이터셋 라벨링 수행 |

## 파이프라인
mermaid
sequenceDiagram
    participant Data as Image Data
    participant Unsup as Analysis (K-means/t-SNE)
    participant Label as Labeling Strategy
    participant Model as YOLOv8
    participant XAI as XAI (Grad-CAM)

    Data->>Unsup: 1. 데이터 분포 분석
    Unsup-->>Data: 군집 중첩 확인 (구분 어려움)
    
    Note over Data, Model: 지도 학습 (YOLOv8) 도입
    
    Label->>Model: 2. [초기] 전체 영역(Full Body) 학습
    Model-->>XAI: 낮은 신뢰도 (0.4 ~ 0.5)
    XAI-->>Label: 원인 분석 (배경/노이즈에 집중됨)
    
    Label->>Model: 3. [개선] 핵심 특징(Key Feature) 학습
    Model-->>Data: 분류 성공 및 신뢰도 향상 (0.6 ~ 0.7)

## 파일 구조

dataset
         train           images  labels
         val             images  labels
         test             images  labels
         data.yaml









## 📋 Phase 1: 비지도 학습을 이용한 데이터 탐색

초기 단계에서는 모델이 정답 없이 스스로 데이터의 특징을 잡아낼 수 있는지 분석.

- **주요 작업**
    - **Feature Extraction:** 사전 학습된 **ResNet50**을 활용해 부품의 고차원 특징 추출.
    - **Visualization:** **t-SNE** 기법으로 특징들을 2차원 공간에 펼쳐 데이터의 분포를 확인.
    - **Clustering:** **K-means** 알고리즘으로 군집화 수행.

### **🔍 문제 발견**

- 시각화 결과, 두 군집이 명확하게 나뉘지 않고 **중앙 부분에서 데이터들이 서로 겹쳐있는** 현상 확인.

## 📋 Phase 2: 지도 학습 도입과 시행착오

클러스터링 분석을 통해 데이터 분포의 한계를 확인한 후, 정답이 있는 데이터를 모델에게 학습시키고자 YOLO모델을 사용.

- **주요 작업 (전체 객체 라벨링)**
    - **라벨링 전략:** 이미지에서 불필요한 배경을 제거하고, 부품의 전체 외형을 포함하는 바운딩 박스를 그려 모델을 학습.

### **🔍 학습 결과**

- **낮은 신뢰도:** 제품 A와 B를 어느정도 구분하기는 하나, 평균 **신뢰도가 30~40%로 상당히 낮게 예측.**
- **클래스 혼동:** 두 제품의 외형이 너무 비슷하여, 제품에 대해 제품 A와 B를 번갈아 예측하는 'Identity Confusion' 발생.

### **🔍 원인 분석**

- 배경을 제거하더라도 제품 외형이 거의 같아서 모델이 클래스를 결정할만한 핵심적인 차이점을 잘 잡아내지 못한다고 판단.
- **모델의 판단 근거 불명확 문제 인지**
    - 단순히 지표만으로는 모델이 실제로 무엇을 근거로 판단하는지 명확하게 알 수 없어서, 어떤 특징을 보고 판단했는지 시각화 할 필요를 느낌.
- 전체 데이터 양도 충분하지 않아 학습을 반복해도 성능 향상에 한계가 있었고, 에폭을 늘렸더니 오히려 혼란이 더 심해지는 현상이 발생.  **데이터셋 (Train: 50장, Valid: 12장, Test:6장)**

## 📋 Phase 3: 라벨링 전략 변경으로 성능 개선

부품의 차별화된 핵심 부분만을 강조해 모델을 다시 학습시키고, Grad-CAM으로 모델의 시선을 확인.

- **주요 작업(라벨링 전략)**
    - 제품 전체가 아닌, 두 제품의 차이를 결정짓는 특징 영역만 타이트하게 **라벨링**을 진행하고 학습을 새롭게 진행.
    - 모델이 공통 영역이 아니라, **제품별 차이**에 집중하도록 유도.
- **데이터 증강**
    - 부족한 데이터는 **밝기, 각도, 노이즈** 등 실제 제조 현장에서 변할 수 있는 요소들을 반영해 증강하고, 파라미터를 조정.
- **Grad-CAM 시각화로,** 모델이 제품의 어떤 특징을 보고 예측을 진행했는지 확인.

## 📝 학습 결과

- **분류 성공:** 라벨링 전략 수정을 통해 모델이 제품 A와 제품 B를 각각 올바른 클래스로 분류하는 데 성공.
- **신뢰도:** 클래스 분류는 잘 수행하였으나, 평균 신뢰도가 **약 60~70% 정도로 여전히 낮은 수준에 머무름을 확인.**
- **Grad-CAM** 시각화 결과, 모델이 정답 영역이 아닌 **배경이나 그림자 부분**을 보고 예측을 진행하고 있음을 확인.

### 📦 **프로젝트 마무리에 대한 나의 생각.**

본 프로젝트서는 분류 자체는 가능했지만, 전체 정확도와 신뢰도가 약 60~70% 수준에서 정체되는 한계를 경험했습니다. 

실제 사용한 데이터 Train 50장 / Validation 12장 / Test 6장으로, 매우 제한적인 환경이었으며, 이러한 조건에서 에폭을 증가시킬수록 모델이 핵심 특징이 아닌 노이즈까지 학습하며 예측이 불안정해지는 문제를 확인할 수 있었습니다.

특히 Grad-CAM 시각화 결과, 모델이 제품의 핵심 특징이 아닌 **배경, 그림자, 외곽 엣지 영역을 근거로 예측을 수행하는 현상**을 확인하였고, **Bounding Box 라벨링 방식이 개·고양이와 같은 큰 객체 분류**에는 적합할 수 있으나, 미세한 형상 차이를 구분해야 하는 문제에는 구조적인 한계가 있음을 인지하게 되었습니다.

이 경험을 통해 데이터 라벨링 전략이 성능의 상한선을 결정짓는 핵심 요소라는 점을 확인하였습니다.

향후 충분한 데이터 확보와 함께 폴리곤 기반의 정밀 라벨링을 적용한다면, 실무 적용 가능한 수준의 성능까지 목표로 할 수 있을 것 같은 생각이 들었습니다.
